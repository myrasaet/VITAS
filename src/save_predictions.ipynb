{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myras\\Documents\\MYMY\\ACADS\\AY 2023-2024 2ND SEM\\STAT299 - Capstone\\Repo\\VITAS - 5 pathology\\vitas-env\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from constants import base_path, app_n_questions, model_list, pathology_scope, positive_threshold\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{base_path}\\\\input\\\\release_conditions.json\") as f:\n",
    "  disease_dict = json.load(f)\n",
    "if pathology_scope:\n",
    "   disease_list =  pathology_scope\n",
    "else:\n",
    "  disease_list = list(disease_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{base_path}\\\\input\\\\release_evidences.json\") as f:\n",
    "  evidences = json.load(f)\n",
    "evidences_list = []\n",
    "evidences_dict = {}\n",
    "evidences_en_to_code = {}\n",
    "for e in evidences.keys():\n",
    "  # only binary symptoms and antecedents\n",
    "  if (not evidences[e][\"possible-values\"]):\n",
    "    evidences_list.append(e)\n",
    "    evidences_dict[e] = evidences[e][\"question_en\"]\n",
    "    evidences_en_to_code[evidences[e][\"question_en\"]] = e\n",
    "evidences_code_to_en = evidences_dict\n",
    "evidences_list_en = list(evidences_en_to_code.keys())\n",
    "evidences_dict[\"AGE\"] = \"AGE\"\n",
    "evidences_dict[\"SEX\"] = \"SEX\"\n",
    "feature_columns = [\"AGE\", \"SEX\"] + evidences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_question(evidences, questionnaire, feature_embeddings_df):\n",
    "    centroid = np.array([feature_embeddings_df.loc[e].values for e in evidences]).mean(axis=0)\n",
    "    _, indices = questionnaire.kneighbors([centroid])\n",
    "    ask_list = [evidences_list_en[i] for i in indices[0] if evidences_list_en[i] not in evidences]\n",
    "    try:\n",
    "        return ask_list\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evidences(answers, user_evidences, questionnaire, feature_embeddings_df):\n",
    "    ask = True\n",
    "    question_counter = 1 # counts initial evidence sa q0\n",
    "    evidences_en = [evidences_code_to_en[e] for e in user_evidences]\n",
    "    answers_en = [evidences_code_to_en[e] for e in answers if e in evidences_list]\n",
    "    asked = evidences_en.copy()\n",
    "    while question_counter < app_n_questions:\n",
    "      ask =  True\n",
    "      next_question_idx = 0\n",
    "      next_question = get_next_question(evidences_en, questionnaire, feature_embeddings_df)\n",
    "      while ask and (question_counter < app_n_questions):\n",
    "        if next_question[next_question_idx] not in asked:\n",
    "          answer = 1 if next_question[next_question_idx] in answers_en else 0\n",
    "          asked.append(next_question[next_question_idx])\n",
    "          question_counter+=1\n",
    "          if answer==1:\n",
    "            evidences_en.append(next_question[next_question_idx])\n",
    "            ask = False\n",
    "          else:\n",
    "            next_question_idx += 1\n",
    "          if next_question_idx > app_n_questions:\n",
    "            break\n",
    "        else:\n",
    "            next_question_idx += 1\n",
    "    return [evidences_en_to_code[e] for e in evidences_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_proc(df, questionnaire, feature_embeddings_df):\n",
    "    df[\"binary_evidences_all\"] = df[\"EVIDENCES\"].apply(lambda x: [d for d in ast.literal_eval(x) if d in evidences_list])\n",
    "    df[\"binary_evidences_all_count\"] = df[\"binary_evidences_all\"].apply(lambda x: len(x))\n",
    "    df[\"binary_evidences\"] = df[[\"EVIDENCES\", \"INITIAL_EVIDENCE\"]].progress_apply(lambda x: get_evidences(ast.literal_eval(x[0]), [x[1]], questionnaire, feature_embeddings_df), axis=1)\n",
    "    df[\"binary_evidences_count\"] = df[\"binary_evidences\"].apply(lambda x: len(x))\n",
    "    df[\"hit_rate\"] = df[\"binary_evidences_count\"]/df[\"binary_evidences_all_count\"]\n",
    "    hit_rate = df[\"hit_rate\"]\n",
    "    for e in evidences_list:\n",
    "        df[e] = df[\"binary_evidences\"].apply(lambda x: 1 if e in x else 0)\n",
    "    df[\"SEX\"] = df[\"SEX\"].map({'F': 0, 'M': 1})\n",
    "    ftr_df = df[feature_columns + [\"PATHOLOGY\"]]\n",
    "    questionnaire_df = df[[\"binary_evidences_all\", \"binary_evidences\", \"INITIAL_EVIDENCE\"]]\n",
    "    return ftr_df, hit_rate, questionnaire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    pred_list = []\n",
    "    for i in range(len(disease_list)):\n",
    "        if x[i] >= positive_threshold:\n",
    "            pred_list.append({\n",
    "                \"disease\": disease_list[i],\n",
    "                \"probability\": x[i]})\n",
    "    if pred_list:\n",
    "        pred_df = pd.DataFrame(pred_list).set_index('disease')\n",
    "        # return only top 1 - allows ties\n",
    "        pred_df['rank'] = pred_df['probability'].rank(method='min', ascending=False)\n",
    "        pred_df = pred_df.sort_values(by=\"rank\")\n",
    "        pred_df = pred_df[pred_df[\"rank\"]<=1][[\"probability\"]]\n",
    "        if pred_df.shape[0] > 1: # in case of tied rankings\n",
    "            pred_df = pred_df.sample(random_state=1)\n",
    "        return list(pred_df.index)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missed_evidence(actual, asked):\n",
    "    return list(set(actual)^set(asked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(x):\n",
    "    if x[0]:\n",
    "        return [x[0]]==x[1]\n",
    "    else:\n",
    "        return not x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_path}\\\\output\\\\questionnaire\\\\questionnaire.pkl', 'rb') as f:\n",
    "    questionnaire = pickle.load(f)\n",
    "feature_embeddings_df = pd.read_pickle(f'{base_path}\\\\output\\\\questionnaire\\\\questionnaire_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIFFERENTIAL_DIAGNOSIS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PATHOLOGY</th>\n",
       "      <th>EVIDENCES</th>\n",
       "      <th>INITIAL_EVIDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>[['Anemia', 0.25071110167158567], ['Atrial fib...</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>['E_7', 'E_24', 'E_26', 'E_53', 'E_54_@_V_180'...</td>\n",
       "      <td>E_154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>[['Guillain-Barré syndrome', 0.135558991316712...</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>['E_16', 'E_29', 'E_50', 'E_53', 'E_54_@_V_182...</td>\n",
       "      <td>E_171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>[['Influenza', 0.1900250899717378], ['Viral ph...</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>['E_50', 'E_53', 'E_54_@_V_183', 'E_54_@_V_198...</td>\n",
       "      <td>E_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>[['Anemia', 0.18697604010451876], ['Atrial fib...</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>['E_7', 'E_24', 'E_26', 'E_53', 'E_54_@_V_180'...</td>\n",
       "      <td>E_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>[['Boerhaave', 1.0]]</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>['E_53', 'E_54_@_V_71', 'E_54_@_V_112', 'E_54_...</td>\n",
       "      <td>E_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132443</th>\n",
       "      <td>27</td>\n",
       "      <td>[['Viral pharyngitis', 0.22702125813983617], [...</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>['E_41', 'E_48', 'E_53', 'E_54_@_V_161', 'E_55...</td>\n",
       "      <td>E_201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132444</th>\n",
       "      <td>57</td>\n",
       "      <td>[['Acute pulmonary edema', 0.12078088376840804...</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>['E_5', 'E_53', 'E_54_@_V_154', 'E_54_@_V_183'...</td>\n",
       "      <td>E_151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132445</th>\n",
       "      <td>52</td>\n",
       "      <td>[['GERD', 0.24494427036287517], ['Bronchitis',...</td>\n",
       "      <td>F</td>\n",
       "      <td>GERD</td>\n",
       "      <td>['E_53', 'E_54_@_V_112', 'E_54_@_V_161', 'E_54...</td>\n",
       "      <td>E_173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132446</th>\n",
       "      <td>10</td>\n",
       "      <td>[['Epiglottitis', 0.2969684152571116], ['HIV (...</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>['E_53', 'E_54_@_V_179', 'E_54_@_V_192', 'E_55...</td>\n",
       "      <td>E_91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132447</th>\n",
       "      <td>7</td>\n",
       "      <td>[['Myocarditis', 0.31486179044904566], ['Anemi...</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>['E_0', 'E_53', 'E_54_@_V_161', 'E_55_@_V_29',...</td>\n",
       "      <td>E_53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132448 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE                             DIFFERENTIAL_DIAGNOSIS SEX PATHOLOGY  \\\n",
       "0        55  [['Anemia', 0.25071110167158567], ['Atrial fib...   F             \n",
       "1        10  [['Guillain-Barré syndrome', 0.135558991316712...   F             \n",
       "2        68  [['Influenza', 0.1900250899717378], ['Viral ph...   F             \n",
       "3        13  [['Anemia', 0.18697604010451876], ['Atrial fib...   M             \n",
       "4        48                               [['Boerhaave', 1.0]]   M             \n",
       "...     ...                                                ...  ..       ...   \n",
       "132443   27  [['Viral pharyngitis', 0.22702125813983617], [...   M             \n",
       "132444   57  [['Acute pulmonary edema', 0.12078088376840804...   M             \n",
       "132445   52  [['GERD', 0.24494427036287517], ['Bronchitis',...   F      GERD   \n",
       "132446   10  [['Epiglottitis', 0.2969684152571116], ['HIV (...   M             \n",
       "132447    7  [['Myocarditis', 0.31486179044904566], ['Anemi...   F             \n",
       "\n",
       "                                                EVIDENCES INITIAL_EVIDENCE  \n",
       "0       ['E_7', 'E_24', 'E_26', 'E_53', 'E_54_@_V_180'...            E_154  \n",
       "1       ['E_16', 'E_29', 'E_50', 'E_53', 'E_54_@_V_182...            E_171  \n",
       "2       ['E_50', 'E_53', 'E_54_@_V_183', 'E_54_@_V_198...             E_53  \n",
       "3       ['E_7', 'E_24', 'E_26', 'E_53', 'E_54_@_V_180'...             E_53  \n",
       "4       ['E_53', 'E_54_@_V_71', 'E_54_@_V_112', 'E_54_...             E_53  \n",
       "...                                                   ...              ...  \n",
       "132443  ['E_41', 'E_48', 'E_53', 'E_54_@_V_161', 'E_55...            E_201  \n",
       "132444  ['E_5', 'E_53', 'E_54_@_V_154', 'E_54_@_V_183'...            E_151  \n",
       "132445  ['E_53', 'E_54_@_V_112', 'E_54_@_V_161', 'E_54...            E_173  \n",
       "132446  ['E_53', 'E_54_@_V_179', 'E_54_@_V_192', 'E_55...             E_91  \n",
       "132447  ['E_0', 'E_53', 'E_54_@_V_161', 'E_55_@_V_29',...             E_53  \n",
       "\n",
       "[132448 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_df_valid = pd.read_csv(f\"{base_path}\\\\input\\\\release_validate_patients\")\n",
    "diagnosis_df_valid[\"PATHOLOGY\"] = [i if i in disease_list else \"\" for i in diagnosis_df_valid[\"PATHOLOGY\"]]\n",
    "diagnosis_df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132448/132448 [15:33<00:00, 141.91it/s]\n",
      "100%|██████████| 132448/132448 [00:02<00:00, 55501.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get features from questionnaire\n",
    "diagnosis_df_valid, hit_rate, questionnaire_df = data_proc(diagnosis_df_valid, questionnaire, feature_embeddings_df)\n",
    "questionnaire_df[\"missed_evidence\"] = questionnaire_df.progress_apply(lambda x: get_missed_evidence(x[0], x[1]), axis=1)\n",
    "questionnaire_df_path = f\"{base_path}\\\\output\\\\error_analysis_questionnaire\"\n",
    "if not os.path.exists(questionnaire_df_path):\n",
    "    os.makedirs(questionnaire_df_path)\n",
    "questionnaire_df.to_csv(f\"{questionnaire_df_path}\\\\questionnaire_df.csv\")\n",
    "missed_evidences = []\n",
    "for e in questionnaire_df[\"missed_evidence\"]:\n",
    "    if e:\n",
    "        missed_evidences.extend(e)\n",
    "missed_evidences_dict = dict(Counter(missed_evidences).most_common(10))\n",
    "missed_evidences_dict = {evidences_code_to_en[k]:missed_evidences_dict[k] for k in missed_evidences_dict}\n",
    "with open(f\"{questionnaire_df_path}\\\\top_missed_evidences.json\", \"w\") as outfile: \n",
    "    json.dump(missed_evidences_dict, outfile, indent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(model_name):\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    counter = 0\n",
    "    for disease in disease_list:\n",
    "        disease_filename = re.sub('[^a-zA-Z0-9 \\n\\.]', '', disease).replace(\" \", \"_\")\n",
    "        with open(f'{base_path}\\\\output\\\\diseases\\\\{disease_filename}\\\\{model_name}\\\\{disease_filename}_model.pkl', 'rb') as f:\n",
    "            clf_model = pickle.load(f)\n",
    "        diagnosis_df_valid[disease] = np.round(clf_model.predict_proba(diagnosis_df_valid[feature_columns])[:,1], 2)\n",
    "        counter+=1\n",
    "        print(f\"done {counter}: {disease}\")\n",
    "    diagnosis_df_valid[\"predicted_diagnosis\"] = diagnosis_df_valid[disease_list].progress_apply(lambda x: pred(x), axis=1)\n",
    "    diagnosis_df_valid[\"is_matched\"] = diagnosis_df_valid[[\"PATHOLOGY\", \"predicted_diagnosis\"]].progress_apply(lambda x: validate(x), axis=1)\n",
    "    diagnosis_df_valid[[\"PATHOLOGY\", \"predicted_diagnosis\", \"is_matched\"] + disease_list].to_csv(f\"{questionnaire_df_path}\\\\{model_name}\\\\validation_df_all_patients_questionnaire.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating decision_tree...\n",
      "done 1: Tuberculosis\n",
      "done 2: GERD\n",
      "done 3: SLE\n",
      "done 4: HIV (initial infection)\n",
      "done 5: Pulmonary neoplasm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132448/132448 [00:34<00:00, 3808.92it/s]\n",
      "100%|██████████| 132448/132448 [00:01<00:00, 80253.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating random_forest...\n",
      "done 1: Tuberculosis\n",
      "done 2: GERD\n",
      "done 3: SLE\n",
      "done 4: HIV (initial infection)\n",
      "done 5: Pulmonary neoplasm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132448/132448 [00:51<00:00, 2591.24it/s]\n",
      "100%|██████████| 132448/132448 [00:02<00:00, 57399.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gradient_boost...\n",
      "done 1: Tuberculosis\n",
      "done 2: GERD\n",
      "done 3: SLE\n",
      "done 4: HIV (initial infection)\n",
      "done 5: Pulmonary neoplasm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132448/132448 [00:37<00:00, 3524.80it/s]\n",
      "100%|██████████| 132448/132448 [00:01<00:00, 83794.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_list[\"tree-based\"]:\n",
    "    save_preds(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating logistic_regression...\n",
      "done 1: Tuberculosis\n",
      "done 2: GERD\n",
      "done 3: SLE\n",
      "done 4: HIV (initial infection)\n",
      "done 5: Pulmonary neoplasm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132448/132448 [00:35<00:00, 3736.87it/s]\n",
      "100%|██████████| 132448/132448 [00:01<00:00, 86575.25it/s]\n"
     ]
    }
   ],
   "source": [
    "save_preds(\"logistic_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
